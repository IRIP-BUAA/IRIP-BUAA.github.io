---
title: MMViG
author: Anonym
date: 2024-02-09 00:00:00 +0800
categories: [Arxiv]
tags: [IT Dataset]
math: true
pin: false
---

- Paper: [ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling](https://arxiv.org/abs/2402.06118)
- GitHub Link: `None`
- Publisher: `Arxiv`
- Author Affiliation: `The University of Texas at Austin`
- Type
  + [ ] SFT
  + [x] RLHF
- Multi-turn
  + [ ] &#x2714;
  + [x] &#x2716;
- Input Modalities $\rightarrow$ Output Modalities <br />(I: Image, V: Video, A: Audio, 3D: Point Cloud, T: Text, B: Bounding box, Tab: Table, Web: Web page)
  + I+T $\rightarrow$ T
- Source
  + `MS-COCO`
- Method
  + `Manu.`
- I/V/A Scale
  + I
    * `16K`
  + V
    * `Not report`
  + A
    * `Not report`
- Dialog Turn
  + `Not report`
- Instance Scale
  + `16K`
